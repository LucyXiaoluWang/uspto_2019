{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparing the Matching tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using multiple sources of data, matching the data from one source to another was really importan for this project. Thus, we prepared two matching table for the future users who wants to use our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Matching Original Application Numbers to Application IDs (PATSTAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table will match the application numbers which can be found in the publications of each filing to its application ID which can be found in the PATSTAT dataset.\n",
    "\n",
    "**Source:** For creating this table we are use \"1_matching_applnNr_applnId\" table that is created in the \"data_preparation\" step. Please refer to the relevant notebook in \"data_preparation\" directory, for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a892eb320>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '08_matching_applnNrOrig_applnId'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "SELECT \n",
    "    appln_id,\n",
    "    appln_nr_orig\n",
    "FROM `usptobias.data_preparation.1_matching_applnNr_applnId`\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Matching Application PAIR numbers to the Original Application Numbers\n",
    "\n",
    "This table will match the special application numbers found in the USPTO PAIR dataset to the original application numbers found in the publication of patents.\n",
    "\n",
    "**Source:** This table is taken directly from the USPTO PAIR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a89431c18>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '09_matching_applnNrPAIR_applnNrOrig'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "SELECT \n",
    "    application_number_pair AS appln_nr_PAIR, \n",
    "    application_number AS appln_nr_orig\n",
    "FROM `patents-public-data.uspto_oce_pair.match`\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating Attorney Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table contains the attorney names and their unique IDs for each application ID.\n",
    "\n",
    "**Source:** This table is created in the 'data_preparation' step. Please refer to `5_attorney_tables` notebook in the \"./data_preparation\" directory, for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a89475358>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '01_applnId_attorney'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "WITH ApplnLawyer_table AS(\n",
    "    SELECT * EXCEPT(rank)\n",
    "    FROM(\n",
    "        SELECT \n",
    "            *,\n",
    "            ROW_NUMBER() OVER (PARTITION BY appln_nr) AS rank\n",
    "        FROM `usptobias.data_preparation.5_appln_attorney`\n",
    "    )\n",
    "    WHERE rank=1\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    appln_id,\n",
    "    attorney,\n",
    "    attorney_id,\n",
    "    attorney_region_code,\n",
    "    attorney_country_code\n",
    "FROM ApplnLawyer_table AS a\n",
    "INNER JOIN `usptobias.final_dataset.09_matching_applnNrPAIR_applnNrOrig` AS b ON b.appln_nr_PAIR = a.appln_nr\n",
    "LEFT JOIN `usptobias.final_dataset.08_matching_applnNrOrig_applnId` AS c ON c.appln_nr_orig = b.appln_nr_orig\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating A Table Containing Inventors, Applicants, and Claims information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source:** This table is created in the 'data_preparation' step. Please refer to `4_invtAppltClaim_appln` notebook in the \"./data_preparation\" directory, for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8948fe80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '02_applnId_publn'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "SELECT \n",
    "    appln_id, publn_auth, publn_kind, publn_claims_earliest, publn_claims_grant, \n",
    "    publn_date_earliest, publn_date_grant, nb_applt, nb_invt\n",
    "FROM `usptobias.data_preparation.4_invtAppltClaim_appln`\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Creating Inventors Table Using USPTO PAIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table contains inventors information that have been extracted from the USPTO PAIR dataset.\n",
    "\n",
    "**Source:** For preparing this table we use `3_appln_uspto` table that is created in the data preparation step (more information: './data_preparation/3_appln_uspto' notebook) and `all_inventors` table form USPTO PAIR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8a4b2208>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '03_appln_inventors_uspto'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "SELECT \n",
    "    appln_id,\n",
    "    UPPER(inventor_name_first) AS invt_name_first,\n",
    "    UPPER(inventor_name_middle) AS invt_name_middle,\n",
    "    UPPER(inventor_name_last) AS invt_name_last,\n",
    "    inventor_rank AS invt_seq_nr,\n",
    "    (CASE WHEN inventor_country_code='US' THEN 1 ELSE 0 END) AS is_US_resident,\n",
    "    inventor_country_code AS invt_country_code\n",
    "FROM `patents-public-data.uspto_oce_pair.all_inventors` AS a\n",
    "INNER JOIN `usptobias.final_dataset.09_matching_applnNrPAIR_applnNrOrig` AS b ON b.appln_nr_PAIR=a.application_number\n",
    "LEFT JOIN `usptobias.final_dataset.08_matching_applnNrOrig_applnId` AS c ON c.appln_nr_orig = b.appln_nr_orig\n",
    "INNER JOIN `usptobias.data_preparation.3_appln_uspto` AS d USING(appln_id)\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Creating Examiners Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table contains examiners' names with their unique ID.\n",
    "\n",
    "**Source:** For creating this table, we are using the `3_appln_uspto` tabel that is created in the \"data_prepration\" step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8a4b7fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '04_examiners_uspto'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "SELECT\n",
    "    examiner_id,\n",
    "    examiner_name.first AS examiner_name_first,\n",
    "    examiner_name.middle AS examiner_name_middle,\n",
    "    examiner_name.last AS examiner_name_last,\n",
    "    examiner_art_unit\n",
    "FROM(\n",
    "    SELECT \n",
    "        examiner_id,\n",
    "        ANY_VALUE(examiner_name) AS examiner_name, \n",
    "        MAX(examiner_art_unit) AS examiner_art_unit\n",
    "    FROM `usptobias.data_preparation.3_appln_uspto`\n",
    "    GROUP BY examiner_id\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Creating Application info Table Using USPTO PAIR Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this table, we many different information for each application that will be used in the analyzing step. This information includes: filing date, grant_date, small_entity, examiner ID, examiner art unit, number of office actions, number of transactions, and many more.\n",
    "\n",
    "**Source:** For creating this table, we use the `3_appln_uspto` and `7_officeAction_category` tabels that are created in the \"data_prepration\" step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8a4dbef0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '05_applnInfo_uspto'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "WITH transactions_t AS(\n",
    "    SELECT \n",
    "        appln_id, \n",
    "        SUM(CASE WHEN transactions.event_code='CTNF' OR transactions.event_code='CTFR' THEN 1 ELSE 0 END) as nb_rejection,\n",
    "        COUNT(transactions.event_code) AS nb_transaction\n",
    "    FROM `usptobias.data_preparation.3_appln_uspto` a, a.transactions\n",
    "    GROUP BY appln_id\n",
    "), t1 AS(\n",
    "    SELECT transaction, category \n",
    "    FROM `usptobias.data_preparation.7_officeAction_category`\n",
    "), t2 AS(\n",
    "    SELECT \n",
    "        appln_id, \n",
    "        transactions\n",
    "    FROM `usptobias.data_preparation.3_appln_uspto` a, a.transactions\n",
    "), t3 AS(\n",
    "SELECT appln_id, transaction AS event_code, category AS transaction_cat\n",
    "FROM t2\n",
    "LEFT JOIN t1 ON t2.transactions.event_code=t1.transaction\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    appln_id AS appln_id,\n",
    "    ANY_VALUE(appln_type) AS appln_type,\n",
    "    ANY_VALUE(PARSE_DATE(\"%F\",filing_date)) AS filing_date,\n",
    "    ANY_VALUE(PARSE_DATE(\"%F\", grant_date)) AS grant_date,\n",
    "    ANY_VALUE(PARSE_DATE(\"%F\", issue_date)) AS issue_date,\n",
    "    ANY_VALUE(PARSE_DATE(\"%F\", abandon_date)) AS abandon_date,\n",
    "    ANY_VALUE(small_entity) AS small_entity,\n",
    "    ANY_VALUE(disposal_type) AS disposal_type,\n",
    "    ANY_VALUE(examiner_id) AS examiner_id,\n",
    "    ANY_VALUE(examiner_art_unit) AS examiner_art_unit,\n",
    "    MAX(ARRAY_LENGTH(actions)) AS nb_office_actions,\n",
    "    MAX(nb_rejection) AS nb_rejection,\n",
    "    MAX(nb_transaction) AS nb_transaction,\n",
    "    COUNT(CASE WHEN transaction_cat='EX' THEN 1 END) AS nb_transaction_ex,\n",
    "    COUNT(CASE WHEN transaction_cat='AA' THEN 1 END) AS nb_transaction_aa,\n",
    "    ANY_VALUE(patent_nr) AS patent_nr,\n",
    "    ANY_VALUE(status_code) AS status_code,\n",
    "    MAX(EXTRACT(DATE FROM PARSE_TIMESTAMP(\"%d%b%Y%t%X\", status_date))) AS status_date\n",
    "FROM `usptobias.data_preparation.3_appln_uspto`\n",
    "LEFT JOIN transactions_t USING(appln_id)\n",
    "LEFT JOIN t3 USING(appln_id)\n",
    "GROUP BY appln_id\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Creating Custom Family ID table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table contains the application IDs and the assigned custom family ID.\n",
    "\n",
    "**Source:** For creating this table we use `Cutom_familyId` table from the \"computing_familyID\" step. Please refer to `./computing_familyID/Custom_FamilyID` for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8b5000b8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '06_family_customDef'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "SELECT \n",
    "    *\n",
    "FROM `usptobias.custom_family.family_customDef`\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Creating Twin Applications Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table contains twin patents, where one of the applications is always from the U.S. jurisdiction.\n",
    "\n",
    "**Source:** For creating this table we use `twin_appln` table from \"computing_family\" step. Please refer to `./computing_familyID/Custom_FamilyID` notebook, for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8b510828>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '07_twin_appln'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "SELECT \n",
    "    *\n",
    "FROM `usptobias.custom_family.twin_appln`\n",
    "WHERE appln_auth_2 IN('EP', 'JP', 'CN', 'KR','DE', 'CA', 'AU', 'TW')\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Creating Pure Assignee Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table contains pure assigne information for each application. By pure assignee, we mean assignees that are not listed as inventors.\n",
    "\n",
    "**Source:** For creating this table, we have used `TLS201_APPLN`, `TLS207_PERS_APPLN`, `TLS906_PERSON` table from the PATSTAT dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8b5221d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '10_assignee_appln' # 2_pure_assignee_appln\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "WITH t1 AS(\n",
    "    SELECT appln_id\n",
    "    FROM `usptobias.patstat.tls201`\n",
    "    WHERE appln_auth='US'\n",
    "), t2 AS(\n",
    "        SELECT *\n",
    "        FROM `usptobias.patstat.tls207`\n",
    "        INNER JOIN t1 USING(appln_id)\n",
    "        WHERE applt_seq_nr<>0 AND invt_seq_nr=0\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    appln_id,\n",
    "    person_id AS assignee_id,\n",
    "    b.han_name AS assignee_han_name,\n",
    "    b.psn_sector AS assignee_sector,\n",
    "    applt_seq_nr,\n",
    "    person_ctry_code AS assignee_country_code\n",
    "FROM t2\n",
    "LEFT JOIN `usptobias.patstat.tls906` b USING(person_id)\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Creating Pseudo Fixed Effect Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1. Attorney Pseudo Fixed Effect\n",
    "\n",
    "This table contains attorney pseudo fixed effects on assignees.\n",
    "\n",
    "**Source:** For creating this table we used `01_applnId_attorney`, `10_assignee_appln` from \"final_dataset\" and `TLS201_APPLN` table from PATSTAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8b4f25f8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '11_attorneyPFE_on_assignee'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "WITH assignee AS(\n",
    "    SELECT appln_id, assignee_id\n",
    "    FROM `usptobias.final_dataset.10_assignee_appln`\n",
    "), attorney AS(\n",
    "    SELECT * EXCEPT(row_attorney)\n",
    "    FROM(\n",
    "        SELECT appln_id, attorney_id, ROW_NUMBER() OVER(PARTITION BY appln_id) row_attorney\n",
    "        FROM `usptobias.final_dataset.01_applnId_attorney`\n",
    "    )\n",
    "    WHERE row_attorney=1\n",
    "), attorney_assignee AS(\n",
    "    SELECT\n",
    "        appln_id,\n",
    "        assignee_id,\n",
    "        attorney_id,\n",
    "        CAST(CAST(b.granted AS INT64) AS FLOAT64) granted\n",
    "    FROM assignee\n",
    "    INNER JOIN attorney USING(appln_id)\n",
    "    INNER JOIN (SELECT appln_id, granted FROM `usptobias.patstat.tls201` WHERE appln_auth='US') b USING(appln_id)\n",
    "), attorney_granted AS(\n",
    "    SELECT\n",
    "        attorney_id,\n",
    "        ARRAY_AGG(STRUCT(assignee_id, granted)) assignee_arr\n",
    "    FROM attorney_assignee\n",
    "    GROUP BY attorney_id\n",
    "), attorney_fixed AS(\n",
    "    SELECT \n",
    "        assignee_id,\n",
    "        attorney_id,\n",
    "        ARRAY(SELECT c.granted FROM b.assignee_arr AS c WHERE a.assignee_id<>c.assignee_id) grant_arr\n",
    "    FROM attorney_assignee AS a\n",
    "    INNER JOIN attorney_granted AS b USING(attorney_id)\n",
    ")\n",
    "\n",
    "\n",
    "SELECT\n",
    "    assignee_id,\n",
    "    attorney_id,\n",
    "    AVG(grant_arr) AS grant_rate\n",
    "FROM\n",
    "attorney_fixed AS a, a.grant_arr\n",
    "GROUP BY assignee_id, attorney_id\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2. Art Unit Pseudo Fixed Effect\n",
    "\n",
    "This table contains art unit pseudo fixed effects on assignees.\n",
    "\n",
    "**Source:** For creating this table we used `05_applnInfo_uspto`, `10_assignee_appln` from \"final_dataset\" and `TLS201_APPLN` table from PATSTAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8a4760f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '12_artunitPFE_on_assignee'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "WITH assignee AS(\n",
    "    SELECT appln_id, assignee_id\n",
    "    FROM `usptobias.final_dataset.10_assignee_appln`\n",
    "), artunit_t AS(\n",
    "    SELECT * EXCEPT(row_artunit)\n",
    "    FROM(\n",
    "        SELECT appln_id, examiner_art_unit, ROW_NUMBER() OVER(PARTITION BY appln_id) row_artunit\n",
    "        FROM `usptobias.final_dataset.05_applnInfo_uspto`\n",
    "    )\n",
    "    WHERE row_artunit=1\n",
    "), artunit_assignee AS(\n",
    "    SELECT\n",
    "        appln_id,\n",
    "        assignee_id,\n",
    "        examiner_art_unit,\n",
    "        CAST(CAST(b.granted AS INT64) AS FLOAT64) granted\n",
    "    FROM assignee\n",
    "    INNER JOIN artunit_t USING(appln_id)\n",
    "    INNER JOIN (SELECT appln_id, granted FROM `usptobias.patstat.tls201` WHERE appln_auth='US') b USING(appln_id)\n",
    "), artunit_grant AS(\n",
    "    SELECT\n",
    "        examiner_art_unit,\n",
    "        ARRAY_AGG(STRUCT(assignee_id, granted)) assignee_arr\n",
    "    FROM artunit_assignee\n",
    "    GROUP BY examiner_art_unit\n",
    "), artunit_fixed AS(\n",
    "    SELECT \n",
    "        assignee_id,\n",
    "        examiner_art_unit,\n",
    "        ARRAY(SELECT c.granted FROM b.assignee_arr AS c WHERE a.assignee_id<>c.assignee_id) grant_arr\n",
    "    FROM artunit_assignee AS a\n",
    "    INNER JOIN artunit_grant AS b USING(examiner_art_unit)\n",
    ")\n",
    "\n",
    "\n",
    "SELECT\n",
    "    assignee_id,\n",
    "    examiner_art_unit,\n",
    "    AVG(grant_arr) AS grant_rate\n",
    "FROM artunit_fixed AS a, a.grant_arr\n",
    "GROUP BY assignee_id, examiner_art_unit\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3. Examiner Pseudo Fixed Effect\n",
    "\n",
    "This table contains examiner pseudo fixed effects on assignees.\n",
    "\n",
    "**Source:** For creating this table we used `05_applnInfo_uspto`, `10_assignee_appln` from \"final_dataset\" and `TLS201_APPLN` table from PATSTAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8b514be0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '13_examinerPFE_on_assignee'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "WITH assignee AS(\n",
    "    SELECT appln_id, assignee_id\n",
    "    FROM `usptobias.final_dataset.10_assignee_appln`\n",
    "), examiners AS(\n",
    "    SELECT * EXCEPT(row_examiner)\n",
    "    FROM(\n",
    "        SELECT appln_id, examiner_id, ROW_NUMBER() OVER(PARTITION BY appln_id) row_examiner\n",
    "        FROM `usptobias.final_dataset.05_applnInfo_uspto`\n",
    "    )\n",
    "    WHERE row_examiner=1\n",
    "), examiner_assignee AS(\n",
    "    SELECT\n",
    "        appln_id,\n",
    "        assignee_id,\n",
    "        examiner_id,\n",
    "        CAST(CAST(b.granted AS INT64) AS FLOAT64) granted\n",
    "    FROM assignee\n",
    "    INNER JOIN examiners USING(appln_id)\n",
    "    INNER JOIN (SELECT appln_id, granted FROM `usptobias.patstat.tls201` WHERE appln_auth='US') b USING(appln_id)\n",
    "), examiner_grant AS(\n",
    "    SELECT\n",
    "        examiner_id,\n",
    "        ARRAY_AGG(STRUCT(assignee_id, granted)) assignee_arr\n",
    "    FROM examiner_assignee\n",
    "    GROUP BY examiner_id\n",
    "), examiner_fixed AS(\n",
    "    SELECT \n",
    "        assignee_id,\n",
    "        examiner_id,\n",
    "        ARRAY(SELECT c.granted FROM b.assignee_arr AS c WHERE a.assignee_id<>c.assignee_id) grant_arr\n",
    "    FROM examiner_assignee AS a\n",
    "    INNER JOIN examiner_grant AS b USING(examiner_id)\n",
    ")\n",
    "\n",
    "\n",
    "SELECT\n",
    "    assignee_id,\n",
    "    examiner_id,\n",
    "    AVG(grant_arr) AS grant_rate\n",
    "FROM examiner_fixed AS a, a.grant_arr\n",
    "GROUP BY assignee_id, examiner_id\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Name's Ethnicity Table\n",
    "\n",
    "`14_name_ethnicity` table contains information on the predicted ethnicity of (first name, last name) pairs using [NamePrism API](http://www.name-prism.com/api).\n",
    "\n",
    "**Source:** For creating this table we used predicted ethnicity [NamePrism API](http://www.name-prism.com/api). More information is available in the `Name_Ethnicty_Prediction` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Name's Origin and Gender Tables\n",
    "\n",
    "`15_name_gender` and `16_name_origin` tables contain information on the predicted country of origin and predicted gender of (first name, last name, country of residence) triples using [NamSor API](https://www.namsor.com/).\n",
    "\n",
    "**Source:** For creating this table we used the predicted country of origin and gender from [NamSor API](https://www.namsor.com/). More information is available in the `Name_Origin_Prediction` and `Name_Gender_Prediction` notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Creating Country of Origin and Residence Table\n",
    "\n",
    "This table contains information on the country of origin, country of residence, and ethnicity information of examiners and inventors for each application.  \n",
    "For this purpose, we first need to find the origin, gender, and ethnicty of inventors and examiners using three `14_name_ethnicity`, `15_name_gender`, and `16_name_origin` table. Tables `17_invtOrig_appln` and `17_examOrig_appln` are built for this purpose.  \n",
    "\n",
    "**Source:** For creating this table, we use `14_name_ethnicity`, `15_name_gender`, and `16_name_origin` tables for the prediction data and `03_appln_inventor_uspto` / `04_examiners_uspto` for the inventors/examiners data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8947f7f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '17_invtOrig_appln'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "WITH invnt_table AS(\n",
    "    SELECT \n",
    "        appln_id, invt_name_first, invt_name_middle, invt_name_last, \n",
    "        invt_seq_nr, is_US_resident, IFNULL(invt_country_code, 'NULL') AS invt_country_code\n",
    "    FROM `usptobias.final_dataset.03_appln_inventors_uspto`\n",
    "\n",
    "), gen_table AS(\n",
    "    SELECT \n",
    "        name_first as invt_name_first, name_last AS invt_name_last, \n",
    "        IFNULL(country_code, 'NULL') AS invt_country_code, predicted_gender as invt_gender\n",
    "    FROM `usptobias.final_dataset.15_name_gender` \n",
    "), origin_table AS(\n",
    "    SELECT \n",
    "        name_first AS invt_name_first, name_last AS invt_name_last, country_code,\n",
    "        country_origin, sub_region_origin\n",
    "    FROM `usptobias.final_dataset.16_name_origin`\n",
    "), ethnicity_table AS(\n",
    "    SELECT name_first AS invt_name_first, name_last AS invt_name_last, ethnicity AS invt_ethnicity\n",
    "    FROM `usptobias.final_dataset.14_name_ethnicity`\n",
    "), country_gdp AS(\n",
    "    SELECT country_code AS invt_country_code, gdppc AS invt_gdppc\n",
    "    FROM `usptobias.data_preparation.6_gdppc_country`\n",
    "    WHERE country_code IS NOT NULL\n",
    "), invt_gen_table AS(\n",
    "    SELECT *\n",
    "    FROM invnt_table\n",
    "    LEFT JOIN gen_table USING(invt_name_first, invt_name_last, invt_country_code)\n",
    "    LEFT JOIN country_gdp USING(invt_country_code)\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    appln_id, invt_name_first, invt_name_middle, invt_name_last, invt_seq_nr, is_US_resident, invt_gdppc,\n",
    "    (CASE WHEN invt_country_code<>'NULL' THEN invt_country_code ELSE NULL END) AS invt_country_code,\n",
    "    invt_gender, country_origin As invt_country_origin, sub_region_origin as invt_sub_reg_origin, invt_ethnicity\n",
    "FROM invt_gen_table\n",
    "LEFT JOIN origin_table USING(invt_name_first, invt_name_last)\n",
    "LEFT JOIN ethnicity_table USING(invt_name_first, invt_name_last)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8b540748>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '17_examOrig_appln'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query= \"\"\"\n",
    "WITH examiners AS(\n",
    "    SELECT examiner_id, examiner_name_first, examiner_name_middle, examiner_name_last, examiner_art_unit, 'US' AS country_code\n",
    "    FROM `usptobias.final_dataset.04_examiners_uspto`\n",
    "), gender AS(\n",
    "    SELECT name_first AS examiner_name_first, name_last AS examiner_name_last, country_code, predicted_gender AS examiner_gender\n",
    "    FROM `usptobias.final_dataset.15_name_gender`\n",
    "), origin AS(\n",
    "    SELECT \n",
    "        name_first AS examiner_name_first, name_last AS examiner_name_last, country_code,\n",
    "        country_origin AS examiner_country_origin, \n",
    "        sub_region_origin AS examiner_sub_reg_origin\n",
    "    FROM `usptobias.final_dataset.16_name_origin`\n",
    "), ethnicity_table AS(\n",
    "    SELECT name_first AS examiner_name_first, name_last AS examiner_name_last, ethnicity AS examiner_ethnicity\n",
    "    FROM `usptobias.final_dataset.14_name_ethnicity`\n",
    "), exm_gender AS(\n",
    "    SELECT *\n",
    "    FROM examiners\n",
    "    LEFT JOIN gender USING(examiner_name_first, examiner_name_last, country_code)\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    examiner_id,\n",
    "    examiner_name_first, examiner_name_middle, examiner_name_last,\n",
    "    examiner_art_unit,\n",
    "    examiner_gender,\n",
    "    examiner_country_origin,\n",
    "    examiner_sub_reg_origin,\n",
    "    examiner_ethnicity\n",
    "FROM exm_gender\n",
    "LEFT JOIN origin USING(examiner_name_first, examiner_name_last, country_code)\n",
    "LEFT JOIN ethnicity_table USING(examiner_name_first, examiner_name_last)\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_speaking_countries = ['AG', 'AU', 'BS', 'BB', 'BZ', 'CA', 'DM', 'GD', 'GY', 'IE', 'JM', 'NZ', 'KN', 'LC', 'VC', 'TT', 'UK', 'GB', 'US', #From gov.uk\n",
    "                              'KE', 'MT', 'NA', 'SG', 'GH', #from Wikipedia\n",
    "                              'IN', 'NG', 'PK', 'RW', 'ZA', 'UG', 'ZW'] #  from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x26a8b581b38>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "query_params = [\n",
    "    bigquery.ArrayQueryParameter('english_speaking_countries', 'STRING', english_speaking_countries)\n",
    "]\n",
    "\n",
    "job_config.query_parameters = query_params\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '17_appln_examInvtOrigin'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "## Note: Here I used MAX() for getting the numbers, since for any CASE where the first two conditions are not met, \n",
    "##...then we will get -1 (if that auth exists in docdb_family).\n",
    "query= \"\"\"\n",
    "WITH appln_t AS(\n",
    "    SELECT appln_id_1 AS appln_id, ARRAY_AGG(appln_id_2) AS twins_array\n",
    "    FROM `usptobias.final_dataset.07_twin_appln`\n",
    "    GROUP BY appln_id\n",
    "), invt_t AS(\n",
    "    SELECT \n",
    "        appln_id, \n",
    "        ARRAY_AGG(invt_country_origin) AS invt_country_array, \n",
    "        ARRAY_AGG(invt_sub_reg_origin) AS invt_region_array,\n",
    "        (CASE WHEN AVG(CASE WHEN invt_country_code IN('UK', 'GB',  'US', 'CA', 'NZ', 'AU', 'IE') THEN 1 ELSE 0 END)>0.5 THEN 1 \n",
    "         ELSE 0 END) AS invt_angSax,\n",
    "        (CASE WHEN AVG(CASE WHEN invt_country_code IN UNNEST(@english_speaking_countries) THEN 1 ELSE 0 END)>0.5 THEN 1\n",
    "         ELSE 0 END) AS invt_eng,\n",
    "        (CASE WHEN AVG(CASE WHEN invt_country_code IN('US') THEN 0 ELSE 1 END)>0 THEN 1\n",
    "         ELSE 0 END) AS invt_foreign,\n",
    "        MAX(CASE WHEN invt_country_code IN('US') THEN 0 ELSE 1 END) AS invt_foreign_exist,\n",
    "        (CASE WHEN AVG(CASE WHEN invt_gender='male' THEN 0 WHEN invt_gender='female' THEN 1 END)>0.5 THEN 1\n",
    "         ELSE 0 END) AS invt_female,\n",
    "        (CASE WHEN AVG(CASE WHEN invt_ethnicity='Muslim' THEN 1 ELSE 0 END)>0.5 THEN 1\n",
    "         ELSE 0 END) AS invt_muslim,\n",
    "        #MAX(CASE WHEN invt_ethnicity='Muslim' THEN 1 ELSE 0 END) AS invt_muslim,\n",
    "        (CASE WHEN AVG(CASE WHEN invt_country_origin IN('CN')  THEN 1 ELSE 0 END)>0.5 THEN 1\n",
    "         ELSE 0 END) AS invt_chinese,\n",
    "         #MAX(CASE WHEN invt_country_origin='CN' THEN 1 ELSE 0 END) AS invt_chinese,\n",
    "        (CASE WHEN AVG(CASE WHEN invt_country_origin IN('JP')  THEN 1 ELSE 0 END)>0.5 THEN 1\n",
    "         ELSE 0 END) AS invt_japanese,\n",
    "        MAX(invt_gdppc) AS invt_gdppc,\n",
    "        (CASE WHEN AVG(CASE WHEN invt_ethnicity='EastAsian' THEN 1 ELSE 0 END)>0.5 THEN 1\n",
    "         ELSE 0 END) AS invt_eastasian,\n",
    "        (CASE WHEN AVG(CASE WHEN invt_country_code IN('CN')  THEN 1 ELSE 0 END)>0.5 THEN 1\n",
    "         ELSE 0 END) AS invt_res_china\n",
    "    FROM `usptobias.final_dataset.17_invtOrig_appln`\n",
    "    GROUP BY appln_id\n",
    "), t1 AS(\n",
    "    SELECT \n",
    "        examiner_id, examiner_country_origin, examiner_sub_reg_origin, examiner_ethnicity, \n",
    "        (CASE WHEN examiner_gender='male' THEN 0 WHEN examiner_gender='female' THEN 1 END) AS examiner_female\n",
    "    FROM `usptobias.final_dataset.17_examOrig_appln`\n",
    "), exam_t AS(\n",
    "    SELECT \n",
    "        appln_id, examiner_id, examiner_country_origin, examiner_sub_reg_origin, examiner_female,\n",
    "        (CASE WHEN examiner_ethnicity='Muslim' THEN 1 ELSE 0 END) AS examiner_muslim,\n",
    "        (CASE WHEN examiner_country_origin IN('CN')  THEN 1 ELSE 0 END) AS examiner_chinese,\n",
    "        (CASE WHEN examiner_country_origin IN('JP')  THEN 1 ELSE 0 END) AS examiner_japanese,\n",
    "        (CASE WHEN examiner_country_origin IN('US')  THEN 1 ELSE 0 END) AS examiner_US\n",
    "    FROM(\n",
    "        SELECT appln_id, examiner_id\n",
    "        FROM `usptobias.final_dataset.05_applnInfo_uspto`\n",
    "    ) AS a\n",
    "    LEFT JOIN t1 USING(examiner_id)\n",
    "), assignee_t AS(\n",
    "    SELECT \n",
    "        appln_id, \n",
    "        (CASE WHEN AVG(CASE WHEN assignee_country_code IN('CN') THEN 1 ELSE 0 END)>0.5 THEN 1\n",
    "         ELSE 0 END) AS assignee_china\n",
    "    FROM `usptobias.final_dataset.10_assignee_appln`\n",
    "    GROUP BY appln_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    appln_id,\n",
    "    (CASE \n",
    "        WHEN ARRAY_LENGTH(invt_country_array)=0 THEN NULL\n",
    "        WHEN examiner_country_origin IN((SELECT invt_country FROM UNNEST(invt_country_array) AS invt_country)) THEN 1 \n",
    "     ELSE 0 END) AS same_country_origin,\n",
    "    (CASE \n",
    "        WHEN ARRAY_LENGTH(invt_region_array)=0 THEN NULL\n",
    "        WHEN examiner_sub_reg_origin IN((SELECT invt_region FROM UNNEST(invt_region_array) AS invt_region)) THEN 1 \n",
    "     ELSE 0 END) AS same_reg_origin,\n",
    "    examiner_muslim,\n",
    "    examiner_chinese,\n",
    "    examiner_japanese,\n",
    "    examiner_female,\n",
    "    examiner_US,\n",
    "    examiner_country_origin,\n",
    "    invt_angSax,\n",
    "    invt_eng,\n",
    "    invt_foreign,\n",
    "    invt_foreign_exist,\n",
    "    invt_muslim,\n",
    "    invt_chinese,\n",
    "    invt_japanese,\n",
    "    invt_female,\n",
    "    invt_gdppc,\n",
    "    invt_eastasian,\n",
    "    invt_res_china,\n",
    "    assignee_china\n",
    "FROM appln_t\n",
    "LEFT JOIN invt_t USING(appln_id)\n",
    "LEFT JOIN exam_t USING(appln_id)\n",
    "LEFT JOIN assignee_t USING(appln_id)\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Creating Patent Portfolio Size for Each Assignee\n",
    "\n",
    "This table contains information on the number of patents that the assginee of each application has filed in the U.S. jurisdiction and within the last 5 years of the current application filing date.   \n",
    "\n",
    "**Source:** For creating this table, we use `10_assignee_appln` from \"final dataset\" and `TLS201_APPLN` from the PATSTAT dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '18_appln_portfolioSize'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "query=\"\"\"\n",
    "WITH t1 AS(\n",
    "    SELECT appln_id, assignee_id, appln_filing_date AS filing_date\n",
    "    FROM `usptobias.final_dataset.10_assignee_appln`\n",
    "    LEFT JOIN (\n",
    "        SELECT appln_id, appln_filing_date, appln_auth\n",
    "        FROM  `usptobias.patstat.tls201`\n",
    "    ) USING(appln_id)\n",
    "    WHERE appln_auth='US'\n",
    "), t2 AS(\n",
    "    SELECT assignee_id, ARRAY_AGG(STRUCT(appln_id, filing_date)) AS filing_arr\n",
    "    FROM t1\n",
    "    GROUP BY assignee_id\n",
    "), t3 AS(\n",
    "    SELECT\n",
    "        t1.appln_id,\n",
    "        t2.assignee_id,\n",
    "        t1.filing_date AS filing_date_curr,\n",
    "        t2.filing_arr\n",
    "    FROM t1\n",
    "    INNER JOIN t2 ON t1.assignee_id=t2.assignee_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    t3.appln_id, \n",
    "    COUNT(CASE WHEN (filing_date_curr>f_list.filing_date) AND \n",
    "                    (DATE_SUB(filing_date_curr, INTERVAL 5 YEAR)<f_list.filing_date) \n",
    "               THEN 1 END) AS portfolio_size\n",
    "FROM t3, UNNEST(t3.filing_arr) AS f_list\n",
    "GROUP BY t3.appln_id\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Running the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Creating Grant Outcome Information Table\n",
    "\n",
    "This table contains the granting outcome data of the '8' jurisdictions and also the information of the average granting rate for the twins in these jurisdictions.\n",
    "These eight jurisdictions are 'EP', 'JP', 'CN', 'KR', 'DE', 'CA', 'AU', 'TW'.\n",
    "\n",
    "**Source:** For creating this table, we use `07_twin_appln` table from \"final dataset\" and `TLS201_APPLN` from the PATSTAT dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '19_appln_grantInfo'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "## Note: Here I used MAX() for getting the numbers, since for any CASE where the first two conditions are not met, \n",
    "##...then we will get -1 (if that auth exists in docdb_family).\n",
    "query= \"\"\"\n",
    "WITH t0 AS(\n",
    "    SELECT appln_id, docdb_family_id\n",
    "    FROM `usptobias.patstat.tls201` AS a\n",
    "    WHERE appln_auth='US'\n",
    "), t1 AS(\n",
    "    SELECT \n",
    "        a.appln_id,\n",
    "        ARRAY_AGG(b.appln_auth) AS docdb_auth_array,\n",
    "        AVG(CAST(CAST(b.granted AS INT64) AS FLOAT64)) AS docdb_avg_grant,\n",
    "        COUNT(DISTINCT b.appln_auth) AS nb_docdb_appln_auth\n",
    "    FROM(####\n",
    "        SELECT appln_id, docdb_family_id\n",
    "        FROM `usptobias.patstat.tls201` AS a\n",
    "        WHERE appln_auth='US'\n",
    "    ) AS a\n",
    "    LEFT JOIN (\n",
    "        SELECT *\n",
    "        FROM `usptobias.patstat.tls201`\n",
    "        WHERE appln_auth IN('EP', 'JP', 'CN', 'KR','DE', 'CA', 'AU', 'TW')\n",
    "    ) AS b ON a.docdb_family_id=b.docdb_family_id\n",
    "    GROUP BY a.appln_id\n",
    "), t2 AS(\n",
    "    SELECT *\n",
    "    FROM `usptobias.final_dataset.07_twin_appln` \n",
    "    WHERE appln_auth_2 IN('EP', 'JP', 'CN', 'KR','DE', 'CA', 'AU', 'TW')\n",
    "), t3 AS(\n",
    "    SELECT \n",
    "        appln_id_1 AS appln_id, \n",
    "        AVG(CAST(CAST(granted_2 AS INT64) AS FLOAT64)) AS twins_avg_grant,\n",
    "        COUNT(DISTINCT appln_auth_2) AS nb_twins_appln_auth\n",
    "    FROM `usptobias.final_dataset.07_twin_appln` \n",
    "    GROUP BY appln_id_1\n",
    "), t4 AS(\n",
    "    SELECT \n",
    "        a.*,\n",
    "        docdb_auth_array AS docdb_auth_array_US,\n",
    "        docdb_avg_grant,\n",
    "        nb_docdb_appln_auth,\n",
    "        twins_avg_grant,\n",
    "        nb_twins_appln_auth\n",
    "    FROM t2 AS a\n",
    "    LEFT JOIN t1 ON a.appln_id_1=t1.appln_id\n",
    "    LEFT JOIN t3 ON a.appln_id_1=t3.appln_id\n",
    ") \n",
    "\n",
    "SELECT \n",
    "    appln_id_1 AS appln_id_US,\n",
    "    ANY_VALUE(family_id) AS family_id,\n",
    "    ANY_VALUE(appln_filing_year_1) AS appln_filing_year_US,\n",
    "    ANY_VALUE(CAST(granted_1 AS INT64)) AS granted_US,\n",
    "    ANY_VALUE(docdb_avg_grant) AS docdb_avg_grant,\n",
    "    ANY_VALUE(nb_docdb_appln_auth) AS nb_docdb_appln_auth,\n",
    "    ANY_VALUE(twins_avg_grant) AS twins_avg_grant,\n",
    "    ANY_VALUE(nb_twins_appln_auth) AS nb_twins_appln_auth,\n",
    "    MAX(CASE \n",
    "        WHEN appln_auth_2='EP' AND granted_2=True THEN 1\n",
    "        WHEN appln_auth_2='EP' AND granted_2=FALSE THEN 0\n",
    "        WHEN (SELECT 'EP' IN UNNEST(docdb_auth_array_US))=TRUE THEN -1\n",
    "    END) AS twin_EP,\n",
    "    MAX(CASE \n",
    "        WHEN appln_auth_2='JP' AND granted_2=True THEN 1\n",
    "        WHEN appln_auth_2='JP' AND granted_2=FALSE THEN 0\n",
    "        WHEN (SELECT 'JP' IN UNNEST(docdb_auth_array_US))=TRUE THEN -1\n",
    "    END) AS twin_JP,\n",
    "    MAX(CASE \n",
    "        WHEN appln_auth_2='CN' AND granted_2=True THEN 1\n",
    "        WHEN appln_auth_2='CN' AND granted_2=FALSE THEN 0\n",
    "        WHEN (SELECT 'CN' IN UNNEST(docdb_auth_array_US))=TRUE THEN -1\n",
    "    END) AS twin_CN,\n",
    "    MAX(CASE \n",
    "        WHEN appln_auth_2='KR' AND granted_2=True THEN 1\n",
    "        WHEN appln_auth_2='KR' AND granted_2=FALSE THEN 0\n",
    "        WHEN (SELECT 'KR' IN UNNEST(docdb_auth_array_US))=TRUE THEN -1\n",
    "    END) AS twin_KR,\n",
    "    MAX(CASE \n",
    "        WHEN appln_auth_2='DE' AND granted_2=True THEN 1\n",
    "        WHEN appln_auth_2='DE' AND granted_2=FALSE THEN 0\n",
    "        WHEN (SELECT 'DE' IN UNNEST(docdb_auth_array_US))=TRUE THEN -1\n",
    "    END) AS twin_DE,\n",
    "    MAX(CASE \n",
    "        WHEN appln_auth_2='CA' AND granted_2=True THEN 1\n",
    "        WHEN appln_auth_2='CA' AND granted_2=FALSE THEN 0\n",
    "        WHEN (SELECT 'CA' IN UNNEST(docdb_auth_array_US))=TRUE THEN -1\n",
    "    END) AS twin_CA,\n",
    "    MAX(CASE \n",
    "        WHEN appln_auth_2='AU' AND granted_2=True THEN 1\n",
    "        WHEN appln_auth_2='AU' AND granted_2=FALSE THEN 0\n",
    "        WHEN (SELECT 'AU' IN UNNEST(docdb_auth_array_US))=TRUE THEN -1\n",
    "    END) AS twin_AU,\n",
    "    MAX(CASE \n",
    "        WHEN appln_auth_2='TW' AND granted_2=True THEN 1\n",
    "        WHEN appln_auth_2='TW' AND granted_2=FALSE THEN 0\n",
    "        WHEN (SELECT 'TW' IN UNNEST(docdb_auth_array_US))=TRUE THEN -1\n",
    "    END) AS twin_TW\n",
    "    \n",
    "FROM t4\n",
    "GROUP BY appln_id_1\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. Creating the Final Table For the Analysis\n",
    "\n",
    "This table contains the final key variables from all the necessary tables in the \"final_dataset\" for applications with the filing year between 2002 and 2012 that are needed for conducting our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "# Creating Job Config\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "#job_config.dry_run = True\n",
    "job_config.use_query_cache = False\n",
    "# Set configuration.query.writeDisposition\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set the destination table\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '20_final_table'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "## Note: Here I used MAX() for getting the numbers, since for any CASE where the first two conditions are not met, \n",
    "##...then we will get -1 (if that auth exists in docdb_family).\n",
    "query= \"\"\"\n",
    "WITH t1 AS(\n",
    "    SELECT appln_id, attorney_id\n",
    "    FROM `usptobias.final_dataset.01_applnId_attorney`\n",
    "), t2 AS(\n",
    "    SELECT *\n",
    "    FROM `usptobias.final_dataset.02_applnId_publn`\n",
    "), t3 AS(\n",
    "    SELECT *\n",
    "    FROM `usptobias.final_dataset.05_applnInfo_uspto`\n",
    "), t4 AS(\n",
    "    SELECT *\n",
    "    FROM `usptobias.final_dataset.19_appln_grantInfo`\n",
    "), t5 AS(\n",
    "    SELECT *\n",
    "    FROM `usptobias.final_dataset.17_appln_examInvtOrigin`\n",
    "    WHERE examiner_muslim IS NOT NULL AND invt_eng IS NOT NULL\n",
    "), t6 AS(\n",
    "    SELECT appln_id, assignee_id\n",
    "    FROM `usptobias.final_dataset.10_assignee_appln`\n",
    "), t7 AS(\n",
    "    SELECT assignee_id, attorney_id, grant_rate AS attorney_FE\n",
    "    FROM `usptobias.final_dataset.11_attorneyPFE_on_assignee`\n",
    "), t8 AS(\n",
    "    SELECT assignee_id, examiner_id, grant_rate AS examiner_FE\n",
    "    FROM `usptobias.final_dataset.13_examinerPFE_on_assignee`\n",
    "), t9 AS(\n",
    "    SELECT assignee_id, examiner_art_unit, grant_rate AS artunit_FE\n",
    "    FROM `usptobias.final_dataset.12_artunitPFE_on_assignee`\n",
    "), t10 AS(\n",
    "    SELECT appln_id, portfolio_size\n",
    "    FROM `usptobias.final_dataset.18_appln_portfolioSize`\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    t4.*,\n",
    "    t1.attorney_id AS attorney_id_US,\n",
    "    t2.publn_claims_earliest AS publn_claims_earliest_US, t2.publn_claims_grant AS publn_claims_grant, \n",
    "    t2.publn_date_earliest AS publn_date_earliest_US, t2.publn_date_grant AS publn_date_grant_US, \n",
    "    t2.nb_applt AS nb_applt_US, t2.nb_invt AS nb_invt_US,\n",
    "    t3.* EXCEPT(appln_id),\n",
    "    t5.* EXCEPT(appln_id),\n",
    "    t6.assignee_id,\n",
    "    t7.attorney_FE,\n",
    "    t8.examiner_FE,\n",
    "    t9.artunit_FE,\n",
    "    t10.portfolio_size\n",
    "FROM t4\n",
    "LEFT JOIN t1 ON t4.appln_id_US=t1.appln_id\n",
    "LEFT JOIN t2 ON t4.appln_id_US=t2.appln_id\n",
    "LEFT JOIN t3 ON t4.appln_id_US=t3.appln_id\n",
    "LEFT JOIN t5 ON t4.appln_id_US=t5.appln_id\n",
    "LEFT JOIN t6 ON t4.appln_id_US=t6.appln_id\n",
    "LEFT JOIN t10 ON t4.appln_id_US=t10.appln_id\n",
    "LEFT JOIN t7 ON t6.assignee_id=t7.assignee_id AND t1.attorney_id=t7.attorney_id\n",
    "LEFT JOIN t8 ON t6.assignee_id=t8.assignee_id AND t3.examiner_id=t8.examiner_id\n",
    "LEFT JOIN t9 ON t6.assignee_id=t9.assignee_id AND t3.examiner_art_unit=t9.examiner_art_unit\n",
    "WHERE appln_filing_year_US BETWEEN 2002 AND 2012\n",
    "\"\"\"\n",
    "\n",
    "# Defining the query\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2. Exporting the Final Table Into a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exporting the Final Table\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Set Source table\n",
    "project_id = 'usptobias'\n",
    "dataset_id = 'final_dataset'\n",
    "table_id = '20_final_table'\n",
    "table_ref = client.dataset(dataset_id, project=project_id).table(table_id)\n",
    "\n",
    "# Set Destination\n",
    "dest_bucket = 'uspto-data'\n",
    "dest_folder = 'final_dataset'\n",
    "dest_file_name = 'final_table.csv'\n",
    "dest_uri = \"gs://{0}/{1}/{2}\".format(dest_bucket, dest_folder, dest_file_name)\n",
    "\n",
    "extract_job = client.extract_table(table_ref, dest_uri, location='US')\n",
    "print('Extract job has {} started!'.format(extract_job.job_id))\n",
    "extract_job.result()\n",
    "print('Job has finished and table {} has been exported to {} bucket!'.format(dest_file_name, dest_bucket))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
