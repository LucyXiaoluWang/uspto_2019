{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "%load_ext google.cloud.bigquery\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import chardet\n",
    "import codecs\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disambiguation of Attorney Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a table of raw attorney names\n",
    "\n",
    "In this step, we first remove any non-alphabetic charactersand then we create a table containing raw attorney names and the processed ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query job has b311b384-530a-436f-921d-e27effcd44d2 started!\n",
      "Job has finished!\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "job_config.use_query_cache = False\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set Destination\n",
    "dataset_id = 'data_preparation'\n",
    "table_id = '5_attorney_raw'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query=\"\"\"\n",
    "WITH t1 AS(\n",
    "SELECT *\n",
    "FROM(\n",
    "    SELECT UPPER(REGEXP_REPLACE(\n",
    "                                REGEXP_REPLACE(\n",
    "                                              REGEXP_REPLACE(correspondence_name_line_1, r'[^a-zA-Z\\s]+', ''), \n",
    "                                              r'[\\s]+', ' '),\n",
    "                                r'(^\\s+)|(\\s+$)', ''\n",
    "                                ) \n",
    "                ) AS lawyer,\n",
    "            correspondence_name_line_1 AS raw_lawyer\n",
    "    FROM `patents-public-data.uspto_oce_pair.correspondence_address` \n",
    "    GROUP BY correspondence_name_line_1 \n",
    ")\n",
    "GROUP BY raw_lawyer, lawyer\n",
    "ORDER BY lawyer DESC\n",
    ")\n",
    "\n",
    "SELECT *\n",
    "FROM t1\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "print('Query job has {} started!'.format(query_job.job_id))\n",
    "query_job.result()\n",
    "print('Job has finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the table into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exctracting table\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Set Source table\n",
    "project_id = 'usptobias'\n",
    "dataset_id = 'data_preparation'\n",
    "table_id = '5_attorney_raw'\n",
    "table_ref = client.dataset(dataset_id, project=project_id).table(table_id)\n",
    "\n",
    "# Set Destination\n",
    "dest_bucket = 'uspto-data'\n",
    "dest_folder = 'data_preparation'\n",
    "dest_file_name = '5_attorney_raw.csv'\n",
    "dest_uri = \"gs://{0}/{1}/{2}\".format(dest_bucket, dest_folder, dest_file_name)\n",
    "\n",
    "extract_job = client.extract_table(table_ref, dest_uri, location='US')\n",
    "print('Extract job has {} started!'.format(extract_job.job_id))\n",
    "extract_job.result()\n",
    "print('Job has finished and table {} has been exported to {} bucket!'.format(dest_file_name, dest_bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Disambiguating Using Standardization Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Source***: The standardization rules has been downloaded from the following link:  \n",
    "https://sites.google.com/site/patentdataproject/Home/posts/namestandardizationroutinesuploaded\n",
    "\n",
    "We then preprocessed the rules to prepare them for our purpose. The preprocessed rules can be found in the `./stdname_rules/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 383,806\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lawyer</th>\n",
       "      <th>raw_lawyer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZVI BEKERMAN</td>\n",
       "      <td>ZVI BEKERMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZOE D ZIAKA AND</td>\n",
       "      <td>ZOE D. ZIAKA AND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lawyer        raw_lawyer\n",
       "0     ZVI BEKERMAN      ZVI BEKERMAN\n",
       "1  ZOE D ZIAKA AND  ZOE D. ZIAKA AND"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading \"5_attorney_raw\" table in a Pandas dataframe\n",
    "## You need to first download \"5_attorney_raw.csv\" into the './data/' folder (located in the current path) ...\n",
    "## ... from \"uspto-data/data_preparation\" GCP Bucket\n",
    "data_folder = './data/'\n",
    "df_rawlawyer = pd.read_csv(data_folder+'5_attorney_raw.csv', low_memory=False)\n",
    "print('Number of records: {:,}'.format(df_rawlawyer.shape[0]))\n",
    "df_rawlawyer.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383743, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding trailing and ending space (for using the rule-based disambiguation)\n",
    "df_rawlawyer = df_rawlawyer.dropna()\n",
    "df_rawlawyer.lawyer = df_rawlawyer.lawyer.apply(lambda x: \" \" + x + \" \")\n",
    "df_rawlawyer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the standard rule files\n",
    "from zipfile import ZipFile\n",
    "data_folder = './data/'\n",
    "with ZipFile(data_folder+'stdname_rules.zip', 'r') as file_ref:\n",
    "    file_ref.extractall(data_folder+'stdname_rules/')\n",
    "    \n",
    "files = sorted(os.listdir(data_folder+'stdname_rules/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading standard rules into a dictionary\n",
    "pattern = r'^.*\\\"(.*?)\\\".*?\\\"(.*?)\\\"'\n",
    "std_mapper = dict()\n",
    "\n",
    "decoding = [(2, 1), \n",
    "            (1, 2), \n",
    "            (1, 2), \n",
    "            (2, 1), \n",
    "            (1, 2), \n",
    "            (1, 2)]\n",
    "\n",
    "for dec, file in zip(decoding, files):\n",
    "    encoding = chardet.detect(open(data_folder+'stdname_rules/'+file, \"rb\").read())['encoding']\n",
    "    with codecs.open(data_folder+'stdname_rules/'+file, 'r', encoding=encoding) as text_file:\n",
    "        lines = text_file.readlines()\n",
    "        for line in lines:\n",
    "            key = (re.match(pattern, line)[dec[0]]).rstrip()\n",
    "            value = (re.match(pattern, line)[dec[1]]).rstrip()\n",
    "            std_mapper[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial</th>\n",
       "      <th>mapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&amp; BRO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&amp; BROTHER</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&amp; C</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       initial mapped\n",
       "0       & BRO        \n",
       "1   & BROTHER        \n",
       "2         & C        "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapper = pd.DataFrame(std_mapper, index=['mapped']).T.reset_index(drop=False).rename(columns={'index':'initial'})\n",
    "df_mapper.mapped = ' '\n",
    "df_mapper.initial = df_mapper.initial.apply(lambda x: x+' ')\n",
    "std_mapper = df_mapper.dropna().set_index('initial')['mapped'].to_dict()\n",
    "\n",
    "df_mapper.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting standardization\n",
    "start_t = time.perf_counter()\n",
    "df_rawlawyer.lawyer = df_rawlawyer.lawyer.replace(std_mapper, regex=True).replace(std_mapper, regex=True)\n",
    "end_t = time.perf_counter()\n",
    "diff_t = end_t - start_t\n",
    "print('Total running time was {:,.0f} hours and {:.0f} minutes!'.format(diff_t//3600, (diff_t%3600)//60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stripping the spaces\n",
    "df_rawlawyer.lawyer = df_rawlawyer.lawyer.str.strip()\n",
    "\n",
    "# Getting unique disambiguated lawyers\n",
    "df_lawyer_id = df_rawlawyer[['lawyer']].drop_duplicates().reset_index(drop=True).copy()\n",
    "# Adding unique ID to each lawyer\n",
    "df_lawyer_id = df_lawyer_id.reset_index(drop=False).rename(columns={'index':'lawyer_id'})\n",
    "df_lawyer_id.lawyer_id = df_lawyer_id.lawyer_id + 100000\n",
    "\n",
    "print('Number of unique lawyers: {:,}'.format(df_lawyer_id.shape[0]))\n",
    "df_lawyer_id.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lawyer_merger = pd.merge(df_rawlawyer, df_lawyer_id, on=['lawyer'], how='left')\n",
    "print('Number of records: {:,}'.format(df_lawyer_merger.shape[0]))\n",
    "df_lawyer_merger.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the resulting dataframes\n",
    "df_lawyer_id.to_csv('./data/5_attorneyId.csv', encoding='utf-8', index=False)\n",
    "df_lawyer_merger.to_csv('./data/5_attorney_disambiguated.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating the BigQuery tables using the disambiguated attorney names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job a74cafd4-62ef-486f-b39f-b42a8066f58c\n",
      "Job has finished!\n"
     ]
    }
   ],
   "source": [
    "# Creating \"5_attorneyID\" table\n",
    "# Creating \"lawyer_id_fung\" table\n",
    "bq_client = bigquery.Client()\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField('attorney_id', 'STRING', 'NULLABLE', None, ()),\n",
    "    bigquery.SchemaField('attorney', 'STRING', 'NULLABLE', None, ())\n",
    "]\n",
    "dataset_id = 'data_preparation'\n",
    "dataset_ref = bq_client.dataset(dataset_id)\n",
    "dest_table_name = '5_attorneyID'\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.schema = schema\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "uri = \"gs://uspto-data/data_preparation/5_attorneyId.csv\"\n",
    "\n",
    "load_job = bq_client.load_table_from_uri(\n",
    "    uri, dataset_ref.table(dest_table_name), job_config=job_config\n",
    ")  \n",
    "print(\"Starting job {}\".format(load_job.job_id))\n",
    "load_job.result()\n",
    "print('Job has finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job 8b558291-172d-486e-8700-5a78986c6323\n",
      "Job has finished!\n"
     ]
    }
   ],
   "source": [
    "# Creating \"5_attorney_disambiguated\" table\n",
    "# Creating \"lawyer_id_fung\" table\n",
    "bq_client = bigquery.Client()\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField('attorney', 'STRING', 'NULLABLE', None, ()),\n",
    "    bigquery.SchemaField('raw_attorney', 'STRING', 'NULLABLE', None, ()),\n",
    "    bigquery.SchemaField('attorney_id', 'STRING', 'NULLABLE', None, ())\n",
    "]\n",
    "\n",
    "# Setting the destination table path\n",
    "dataset_id = 'data_preparation'\n",
    "dataset_ref = bq_client.dataset(dataset_id)\n",
    "dest_table_name = '5_attorney_disambiguated'\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.schema = schema\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "uri = \"gs://uspto-data/data_preparation/5_attorney_disambiguated.csv\"\n",
    "\n",
    "load_job = bq_client.load_table_from_uri(\n",
    "    uri, dataset_ref.table(dest_table_name), job_config=job_config\n",
    ")  \n",
    "print(\"Starting job {}\".format(load_job.job_id))\n",
    "\n",
    "load_job.result()\n",
    "print('Job has finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating the final table: `5_appln_attorney`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query job has 5ba0d91a-70bd-43c4-8a0a-77a2fc725415 started!\n",
      "Job has finished!\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "job_config.use_query_cache = False\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "# Set Destination\n",
    "project_id = 'usptobias'\n",
    "dataset_id = 'data_preparation'\n",
    "table_id = '5_appln_attorney'\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "query=\"\"\"\n",
    "WITH rlawyerAppln_table AS(\n",
    "SELECT \n",
    "    application_number AS appln_nr,\n",
    "    correspondence_name_line_1 AS raw_attorney,\n",
    "    correspondence_region_code AS attorney_region_code,\n",
    "    correspondence_country_code AS attorney_country_code\n",
    "FROM `patents-public-data.uspto_oce_pair.correspondence_address`\n",
    "), lawyerMerger_table AS(\n",
    "    SELECT attorney, raw_attorney, attorney_id\n",
    "    FROM `{0}.{1}.5_attorney_disambiguated`\n",
    ")\n",
    "\n",
    "SELECT appln_nr, attorney, attorney_id, attorney_region_code, attorney_country_code\n",
    "FROM rlawyerAppln_table\n",
    "LEFT JOIN lawyerMerger_table USING(raw_attorney)\n",
    "WHERE attorney IS NOT NULL\n",
    "\"\"\".format(project_id, dataset_id)\n",
    "\n",
    "query_job = client.query(query, location='US', job_config=job_config)\n",
    "print('Query job has {} started!'.format(query_job.job_id))\n",
    "query_job.result()\n",
    "print('Job has finished!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
