{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='darkgrid', font_scale=1.5)\n",
    "#sns.set_style('darkgrid', {\"xtick.minor.size\": 10, \"ytick.major.size\": 10})\n",
    "current_palette = sns.color_palette('deep')\n",
    "#sns.palplot(current_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. A Word on Different Family Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. DOCDB family (simple family, or Espacenet patent family)\n",
    "\n",
    "All applications of the same simple family do have the **same priorities**. The technical content of these family members is regarded as **(almost) identical**, so their publications are sometimes called “equivalent”.\n",
    "\n",
    "This means that the applications that **share the same priorities** (Paris Convention or technical relation or others as contained in table `TLS201_APPLN`, `TLS204_PRIOR_APPLN`, `TLS205_TECH_REL` and `TLS216_APPLN_CONTN`) will be assigned to the same family.\n",
    "\n",
    "However, the EPO reserves the right to classify an application into a particular simple family irrespective of this general rule - the EPO does this by creating artificial priorities for an application or by ignoring certain priorities (declaring them “inactive”) for the purpose of family building.\n",
    "\n",
    "\n",
    "By “priority” here, we do not mean only “Paris Convention priority”, but also other types of priorities which link one application to a “prior” application. The various types of priorities are stored in separate tables:\n",
    "1. TLS201_APPLN An PCT application in its regional/national phase contains in its attribute INTERNAT_APPLN_ID the APPLN_ID of its original PCT application\n",
    "2. TLS204_APPLN_PRIOR contains Paris Convention priorities\n",
    "3. TLS205_TECH_REL contains links between technically equivalent applications\n",
    "4. TLS216_APPLN_CONTN contains various relations like continuations, divisional applications, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. INPADOC family (Extended family)\n",
    "\n",
    "All applications of the same extended family are **directly or indirectly** linked to the **same root** priority application. Usually the applications are related to the same technical invention, but their individual content may differ.\n",
    "\n",
    "This means applications that **share the same priority** `directly `or `indirectly` via other applications. \n",
    "A **'priority'** in this case means a **link shown** between applications as in tables `TLS201_APPLN` (regional/national phase of a PCT application), `TLS204_ APPLN_PRIOR` (PARIS convention priorities), `TLS205_TECH_REL` (patents which have been technically linked by patent examiners on the basis of similar content) and table `TLS216_ APPLN_CONTN` (continuations, divisions etc.).\n",
    "\n",
    "*For the dummy application (i.e. APPLN_ID = 0) and for artificial application replenished because of citations (i.e. APPLN_ID > 930 000 000) the value of the INPADOC_FAMILY_ID will be the same as the value of the APPLN_ID. Thus, each \"appln_id\" will have the family size of exactly one.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Our Family ID\n",
    "\n",
    "For constructing our family ID we have used the following algorithm:\n",
    "1. Initialize the `‘Relation’` table with four columns (*‘Parent_ID’, ‘Parent_Authority’, ‘Prior_Set’, ‘Children_Set'*) using three patent linkage tables `‘TLS204_APPL_PRIOR’`, `‘TLS205_TECH_REL’`, and `‘TLS216_APPLN_CONTN’` and the application authority data from `‘TLS201_APPLN’` table. The *‘Parent_ID’* and *‘Parent_Authority’* are the same as *‘Application_ID’* and *‘Application_Authority’*, respectively. The *‘Prior_Set’* is the set of all priority filings that each parent id is pointing to. The children set is the set of all ‘Parent_ID’ that are from the same “Parent_Authority” and have the same “Prior_Set”.  \n",
    "For the applications that are in the table `‘TLS201_APPLN’` but not in the `‘Relation’` table, add their data to the `‘Relation’` table by setting *'Prior_Set'* and *'Children_Set'* initially containing only the *‘Parent_ID’* as their member.\n",
    "2. Initialize the `‘Family’` table with three columns as (*‘Application_ID’*, *‘Application_Authority’*, *'Parent_Set'*), where *‘Application_ID’* and *‘Application_Authority’* are the same as *‘appln_id’* and *‘appln_auth’* columns from `‘TLS201_APPLN’`, respectively. And initially, *'Parent_Set'* is the set containing only its *'Application_ID'* as its member.\n",
    "3. While there exists a *‘Parent_Set’* in the `‘Family’` table that is updated:  \n",
    "     a.\tFor each *‘Application_ID’*, update the parent IDs in the *'Parent_Set'* using (*'Parent_ID'*, *'Prior_Set'*) pairs in `‘Relation’` table, only if the initial *'Parent Set'* (at the beginning of step 3) is a subset of the *'Children Set'* (for those application IDs that are pointing to several priors, add all of them to the parent set). Flag the parent sets that have been changed.\n",
    "4. Assign a unique family ID to each distinct *'Parent_Set'* (applications with the same parent set will be located in the same family).\n",
    "5. Return the final `‘Family’` table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. BigQuery Implementation of Our Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This implementation is slightly different from the above written algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(linkage_table, appln_table, \n",
    "                   relation_table, family_table, \n",
    "                   dataset_id, project_id):\n",
    "    \"\"\"\n",
    "    Initializing the relation and family table\n",
    "    \"\"\"\n",
    "    client = bigquery.Client()\n",
    "    \n",
    "    ##### Initializing the relation table #####\n",
    "    # Creating Job Config\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    #job_config.dry_run = True\n",
    "    job_config.use_query_cache = False\n",
    "    # Set configuration.query.writeDisposition\n",
    "    job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "    # Set the destination table\n",
    "    table_ref = client.dataset(dataset_id, project=project_id).table(relation_table)\n",
    "    job_config.destination = table_ref\n",
    "\n",
    "    query = \"\"\"\n",
    "    WITH t0 AS(\n",
    "        SELECT DISTINCT\n",
    "                appln_id, prior_appln_id, appln_auth\n",
    "        FROM (\n",
    "                SELECT appln_id, prior_appln_id, appln_auth\n",
    "                FROM {}\n",
    "                LEFT JOIN (\n",
    "                        SELECT appln_id, appln_auth\n",
    "                        FROM {}\n",
    "                ) USING(appln_id)\n",
    "        )\n",
    "        UNION ALL (\n",
    "                SELECT \n",
    "                        t2.appln_id AS appln_id, \n",
    "                        t2.appln_id AS prior_appln_id,\n",
    "                        t2.appln_auth AS appln_auth\n",
    "                FROM {} AS t1\n",
    "                RIGHT JOIN (\n",
    "                        SELECT appln_id, appln_auth\n",
    "                        FROM {}\n",
    "                        ) AS t2 ON t1.appln_id=t2.appln_id\n",
    "                WHERE t1.appln_id IS NULL\n",
    "        )\n",
    "    ), t1 AS(\n",
    "        SELECT appln_id, prior_appln_id, appln_auth\n",
    "        FROM t0\n",
    "        GROUP BY appln_id, prior_appln_id, appln_auth\n",
    "    ), a AS(\n",
    "        SELECT *\n",
    "        FROM t1\n",
    "        LEFT JOIN(\n",
    "                SELECT prior_appln_id, appln_auth, ARRAY_AGG(DISTINCT appln_id ORDER BY appln_id) AS children_set\n",
    "                FROM t1\n",
    "                GROUP BY prior_appln_id, appln_auth\n",
    "        ) USING(prior_appln_id, appln_auth)\n",
    "    )\n",
    "    \"\"\".format(linkage_table, appln_table, linkage_table, appln_table)\n",
    "    # Defining the query\n",
    "    query_job = client.query(query, location='US', job_config=job_config)\n",
    "    query_job.result()\n",
    "    \n",
    "    ##### Initializing the family table ######\n",
    "    # Creating Job Config\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    #job_config.dry_run = True\n",
    "    job_config.use_query_cache = False\n",
    "    # Set configuration.query.writeDisposition\n",
    "    job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "    # Set the destination table\n",
    "    table_ref = client.dataset(dataset_id, project=project_id).table(family_table)\n",
    "    job_config.destination = table_ref\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT DISTINCT\n",
    "            appln_id, appln_id AS prior_appln_id, appln_auth, 1 AS updated\n",
    "    FROM {}\n",
    "    GROUP BY appln_id, appln_auth\n",
    "    )\n",
    "    \"\"\".format(appln_table)\n",
    "    # Defining the query\n",
    "    query_job = client.query(query, location='US', job_config=job_config)\n",
    "    query_job.result()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updating_step(relation_table, family_table, \n",
    "                  dataset_id, project_id):\n",
    "    \n",
    "    # Initializing the table names\n",
    "    dest_table = family_table\n",
    "    relation_table = '`{0}.{1}.{2}`'.format(project_id, dataset_id, relation_table)\n",
    "    family_table = '`{0}.{1}.{2}`'.format(project_id, dataset_id, family_table)\n",
    "    \n",
    "    client = bigquery.Client()\n",
    "    # Creating Job Config\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    #job_config.dry_run = True\n",
    "    job_config.use_query_cache = False\n",
    "    # Set configuration.query.writeDisposition\n",
    "    job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "    # Set the destination table\n",
    "    table_ref = client.dataset(dataset_id, project=project_id).table(dest_table)\n",
    "    job_config.destination = table_ref\n",
    "\n",
    "    query=\"\"\"\n",
    "    WITH t1 AS(\n",
    "        SELECT appln_id, prior_appln_id, appln_auth\n",
    "        FROM {}\n",
    "        GROUP BY appln_id, prior_appln_id, appln_auth\n",
    "    ), family_table AS(\n",
    "        SELECT *\n",
    "        FROM t0\n",
    "        LEFT JOIN(\n",
    "                SELECT appln_id, ARRAY_AGG(DISTINCT prior_appln_id ORDER BY prior_appln_id) AS parent_set\n",
    "                FROM t0\n",
    "                GROUP BY appln_id\n",
    "        ) USING(appln_id)\n",
    "    ), joined AS(\n",
    "        SELECT \n",
    "                a.appln_id,\n",
    "                a.prior_appln_id AS prior_appln_b,\n",
    "                b.prior_appln_id AS prior_appln_a,\n",
    "                a.parent_set,\n",
    "                b.children_set,\n",
    "                a.appln_auth\n",
    "        FROM family_table AS a\n",
    "        LEFT JOIN {} AS b ON a.prior_appln_id=b.appln_id\n",
    "    )\n",
    "\n",
    "    SELECT DISTINCT\n",
    "        appln_id,\n",
    "        appln_auth,\n",
    "        (CASE WHEN z=0 THEN prior_appln_a ELSE prior_appln_b END) AS prior_appln_id,\n",
    "        (CASE WHEN z=0 AND prior_appln_a<>prior_appln_b THEN 1 ELSE 0 END) AS updated\n",
    "    FROM \n",
    "        joined AS c,\n",
    "        UNNEST([(\n",
    "                SELECT ARRAY_LENGTH(c.children_set) - COUNT(1) \n",
    "                FROM UNNEST(c.children_set) AS x\n",
    "                JOIN UNNEST(c.parent_set) AS y\n",
    "                ON x=y)]) AS z\n",
    "\n",
    "    \"\"\".format(family_table, relation_table)\n",
    "    \n",
    "    # Defining the query\n",
    "    query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "    query_job.result()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termination_condition(family_table, dataset_id, project_id):\n",
    "    t1 ='`{0}.{1}.{2}`'.format(project_id, dataset_id, family_table)\n",
    "    client = bigquery.Client()\n",
    "    query=\"\"\"\n",
    "    SELECT SUM(updated) AS sum_updated, COUNT(updated) AS nb_rows\n",
    "    FROM {}\n",
    "    \"\"\".format(t1)\n",
    "    return client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cycles(family_table, dest_table, \n",
    "                  dataset_id, project_id):\n",
    "    # Initializing the full table name for family table\n",
    "    family_table = '`{0}.{1}.{2}`'.format(project_id, dataset_id, family_table)\n",
    "    \n",
    "    client = bigquery.Client()\n",
    "    # Creating Job Config\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    #job_config.dry_run = True\n",
    "    job_config.use_query_cache = False\n",
    "    # Set configuration.query.writeDisposition\n",
    "    job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "    # Set the destination table\n",
    "    table_ref = client.dataset(dataset_id, project=project_id).table(dest_table)\n",
    "    job_config.destination = table_ref\n",
    "    \n",
    "    query=\"\"\"\n",
    "    WITH a AS(\n",
    "        SELECT appln_id, ANY_VALUE(appln_auth) AS appln_auth, prior_appln_id, MIN(updated) AS updated\n",
    "        FROM {}\n",
    "        GROUP BY appln_id, prior_appln_id\n",
    "    )\n",
    "        SELECT DISTINCT *\n",
    "        FROM a\n",
    "        WHERE updated=0\n",
    "    \"\"\".format(family_table)\n",
    "\n",
    "    # Defining the query\n",
    "    query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "    query_job.result()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_familyID(family_table, dest_table, dataset_id, project_id):\n",
    "    # Initializing the full table names\n",
    "    family_table = '`{0}.{1}.{2}`'.format(project_id, dataset_id, family_table)\n",
    "    \n",
    "    client = bigquery.Client()\n",
    "    # Creating Job Config\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    #job_config.dry_run = True\n",
    "    job_config.use_query_cache = False\n",
    "    # Set configuration.query.writeDisposition\n",
    "    job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "    # Set the destination table\n",
    "    table_ref = client.dataset(dataset_id, project=project_id).table(dest_table)\n",
    "    job_config.destination = table_ref\n",
    "    query=\"\"\"\n",
    "    WITH b AS(\n",
    "        SELECT\n",
    "            appln_id,\n",
    "            appln_auth,\n",
    "            (CASE WHEN ARRAY_LENGTH(children_set)=1 THEN prior_appln_id ELSE appln_id END) AS prior_appln_id\n",
    "        FROM {0} AS a\n",
    "        LEFT JOIN(\n",
    "                SELECT prior_appln_id, appln_auth, ARRAY_AGG(DISTINCT appln_id ORDER BY appln_id) AS children_set\n",
    "                FROM {0}\n",
    "                GROUP BY prior_appln_id, appln_auth\n",
    "        ) USING(prior_appln_id, appln_auth)\n",
    "    ), a AS(\n",
    "        SELECT \n",
    "            *\n",
    "        FROM b\n",
    "        LEFT JOIN(\n",
    "                SELECT \n",
    "                    appln_id, \n",
    "                    ARRAY_AGG(DISTINCT prior_appln_id ORDER BY prior_appln_id) AS parent_set,\n",
    "                    TO_JSON_STRING(ARRAY_AGG(DISTINCT prior_appln_id ORDER BY prior_appln_id)) AS priors_str\n",
    "                FROM b\n",
    "                GROUP BY appln_id\n",
    "        ) USING(appln_id)\n",
    "    )\n",
    "    \n",
    "    SELECT DISTINCT *\n",
    "    FROM(\n",
    "        SELECT DISTINCT\n",
    "            appln_id,\n",
    "            appln_auth,\n",
    "            family_id\n",
    "        FROM(\n",
    "            SELECT \n",
    "                appln_id,\n",
    "                appln_auth,\n",
    "                c.prior_appln_id\n",
    "            FROM a\n",
    "            LEFT JOIN(\n",
    "                SELECT\n",
    "                    priors_str,\n",
    "                    ANY_VALUE(parent_set) AS parent_set,\n",
    "                    (CASE WHEN ARRAY_LENGTH(ANY_VALUE(parent_set))>1 \n",
    "                          THEN ARRAY_AGG(DISTINCT appln_id ORDER BY appln_id LIMIT 1) \n",
    "                    ELSE ANY_VALUE(parent_set) END) AS prior_appln_id\n",
    "                FROM a\n",
    "                GROUP BY priors_str\n",
    "            ) AS c USING(priors_str)\n",
    "        ) AS t1, UNNEST(t1.prior_appln_id) AS family_id\n",
    "    )\n",
    "    \"\"\".format(family_table)\n",
    "\n",
    "    # Defining the query\n",
    "    query_job = client.query(query, location='US', job_config=job_config)\n",
    "\n",
    "    query_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding family ID\n",
    "def finding_family(linkage_table, appln_table, # The full table path for these two table\n",
    "                   family_table, relation_table, final_table, # Only table names for these table\n",
    "                   dataset_id, project_id):\n",
    "    start_time = time.time()\n",
    "    pbar = tqdm(total=100)\n",
    "    continue_cond = pd.DataFrame(dict(sum_updated=[0], nb_rows=[0]))\n",
    "    \n",
    "    initialization(linkage_table=linkage_table, appln_table=appln_table, \n",
    "                   relation_table=relation_table, family_table=family_table, \n",
    "                   dataset_id=dataset_id, project_id=project_id)\n",
    "    pbar.update(10)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        updating_step(relation_table=relation_table, family_table=family_table, \n",
    "                      dataset_id=dataset_id, project_id=project_id)\n",
    "        previous_updates = continue_cond.loc[0,'sum_updated']\n",
    "        continue_cond = termination_condition(family_table=family_table, \n",
    "                                              dataset_id=dataset_id, \n",
    "                                              project_id=project_id)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        pbar.update(int(80/n_iter))\n",
    "        print('Remaining {:,}/{:,}\\nThere are {:,} elements that has been finished in the previous step!'\n",
    "              .format(continue_cond.loc[0,'sum_updated'], continue_cond.loc[0,'nb_rows'], \n",
    "                      previous_updates - continue_cond.loc[0,'sum_updated']))\n",
    "        if not continue_cond.loc[0,'sum_updated']: \n",
    "            break\n",
    "        \n",
    "    if continue_cond.loc[0,'sum_updated']:\n",
    "        remove_cycles(family_table=family_table, dest_table=final_table,\n",
    "                      dataset_id=dataset_id, project_id=project_id)\n",
    "    pbar.n=90\n",
    "    pbar.last_printed_n =90\n",
    "    computing_familyID(family_table=final_table, dest_table=final_table, \n",
    "                       dataset_id=dataset_id, project_id=project_id)\n",
    "    pbar.update(10)\n",
    "    pbar.close()\n",
    "    print('It took {:.2f} seconds in total.\\nThe number of updates: {} times!'.format(time.time()-start_time, i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
